## 分配内核缓冲区

当一个进程使用命令协议`BC_TRANSACTION`或者`BC_REPLY`向另一个进程传递数据时，Binder驱动就会从用户空间拷贝数据到内核空间，然后再传递给目标进程。这时候Binder驱动就需要再目标进程的.内存池中分配出一小块内核缓冲区来保存这些数据

drivers\staging\android\binder.c

```java
/*
proc:目标进程
data_size：数据区大小
offsets_size：偏移数组大小
is_async：请求的内核缓冲区是用于异步事务还是同步事务,true:异步事务
*/
static struct binder_buffer *binder_alloc_buf(struct binder_proc *proc,
	size_t data_size, size_t offsets_size, int is_async)
{
	
	struct rb_node *n = proc->free_buffers.rb_node;
	struct binder_buffer *buffer;
	size_t buffer_size;
	struct rb_node *best_fit = NULL;
	void *has_page_addr;
	void *end_page_addr;
	size_t size;

	if (proc->vma == NULL) {
		printk(KERN_ERR "binder: %d: binder_alloc_buf, no vma\n",
		       proc->pid);
		return NULL;
	}

	// 数据分为data区的数据（里面包含基本类型的数据和binder对象）
	// 还有offsets数组大小，这里用来记录data区中binder对象的偏移位置
	// 注意这个size只是整个数据的一部分，还有binder_buffer结构体占用的空间
	size = ALIGN(data_size, sizeof(void *)) +
		ALIGN(offsets_size, sizeof(void *));

	// 有溢出，数据太大了
	if (size < data_size || size < offsets_size) {
		binder_user_error("binder: %d: got transaction with invalid "
			"size %zd-%zd\n", proc->pid, data_size, offsets_size);
		return NULL;
	}

    // 如果是异步事务，检查异步事务的内存空间
	// 在binder_mmap时已经将异步事务的内核缓冲区大小为其一半，防止异步事务消耗过多的内核缓冲区
	if (is_async &&
	    proc->free_async_space < size + sizeof(struct binder_buffer)) {
		if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
			printk(KERN_ERR "binder: %d: binder_alloc_buf size %zd f"
			       "ailed, no async space left\n", proc->pid, size);
		return NULL;
	}

    // 在空闲的节点中，查找大小最合适的buffer，空闲节点是以大小为序组织在红黑树中的
	while (n) {
		buffer = rb_entry(n, struct binder_buffer, rb_node);
		BUG_ON(!buffer->free);
		buffer_size = binder_buffer_size(proc, buffer);
		
		if (size < buffer_size) {
			// 红黑树嘛，小的值在左边
			best_fit = n;
			n = n->rb_left;
		} else if (size > buffer_size)
			// 大的值在右边
			n = n->rb_right;
		else {
			best_fit = n;
			break;
		}
	}
	// 该循环结束后，best_fit指向空闲节点中buffer的大小与请求大小最接近且满足请求大小的节点
	if (best_fit == NULL) {
		printk(KERN_ERR "binder: %d: binder_alloc_buf size %zd failed, "
		       "no address space\n", proc->pid, size);
		return NULL;
	}
	// 没有找到大小与请求大小正好的节点(节点拥有的地址空间本次分配后有剩余)，
	// 将buffer和buffer_size修正为best_fit指向节点的地址和大小，
	// 如果找到大小相等的，这两个值已经是正确的了。
	if (n == NULL) {
		buffer = rb_entry(best_fit, struct binder_buffer, rb_node);
		buffer_size = binder_buffer_size(proc, buffer);
	}
	if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
		printk(KERN_INFO "binder: %d: binder_alloc_buf size %zd got buff"
		       "er %p size %zd\n", proc->pid, size, buffer, buffer_size);

	// 该binder_buffer节点所管理的虚拟地址空间最后一页的起始虚拟地址
	// 就是虚拟空间倒数4字节位置的内存地址
	has_page_addr = (void *)(((uintptr_t)buffer->data + buffer_size) & PAGE_MASK);
	if (n == NULL) {
		// 裁剪内核缓冲区，4是4字节，一页就是4字节，物理内存按照一页进行分配
		if (size + sizeof(struct binder_buffer) + 4 >= buffer_size)
			// 节点空闲地址空间在本次分配后不足于容纳其他的binder_buffer
			buffer_size = size; /* no room for other buffers */
		else
			// 多申请一个binder_buffer，记录节点分配后剩余空间的状态
			buffer_size = size + sizeof(struct binder_buffer);
	}
	// 请求地址空间中最后一页的页末地址
	end_page_addr = (void *)PAGE_ALIGN((uintptr_t)buffer->data + buffer_size);
	if (end_page_addr > has_page_addr)
		end_page_addr = has_page_addr;
	
	// 分配物理页框，并和内核态地址和用户地址空间建立映射
	if (binder_update_page_range(proc, 1,
	     // 这里从data开始进行页对齐的原因是：binder_buffer本身所在的页已经分配过物理页框了
	    (void *)PAGE_ALIGN((uintptr_t)buffer->data), end_page_addr, NULL))
		return NULL;

	// 从空闲buffer红黑树中移除该节点
	rb_erase(best_fit, &proc->free_buffers);
	buffer->free = 0;
	// 将分配的binder_buffer插入到已分配地址的红黑树中
	binder_insert_allocated_buffer(proc, buffer);
	
	// 如果找到节点所拥有的buffer大小超过请求分配的大小（外加sizeof(struct binder_buffer) + 4）
	// 则将节点剩余未分配的空间重新插入到空闲buffer的红黑树中
	if (buffer_size != size) {
		struct binder_buffer *new_buffer = (void *)buffer->data + size;
		list_add(&new_buffer->entry, &buffer->entry);
		new_buffer->free = 1;
		binder_insert_free_buffer(proc, new_buffer);
	}
	if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
		printk(KERN_INFO "binder: %d: binder_alloc_buf size %zd got "
		       "%p\n", proc->pid, size, buffer);
	buffer->data_size = data_size;
	buffer->offsets_size = offsets_size;
	buffer->async_transaction = is_async;
	if (is_async) {
		// 如果是异步的，还需要更新异步空间的大小。
		proc->free_async_space -= size + sizeof(struct binder_buffer);
		if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC_ASYNC)
			printk(KERN_INFO "binder: %d: binder_alloc_buf size %zd "
			       "async free %zd\n", proc->pid, size,
			       proc->free_async_space);
	}

	return buffer;
}
```





假如找到了一个buffer使用，但是这个buffer中的buffer_size比申请的还大，那么需要考虑两种情况

1. 剩余的空间还能给下一个binder_buffer使用

![image-20220424010814123](img./image-20220424010814123.png)



2. 分配后，剩下的空间已经不足以给下一个binder_buffer使用

![image-20220424010600539](./img/image-20220424010600539.png)





