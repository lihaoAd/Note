

##  TF-IDF

TF的意思是词频(Term - frequency)，IDF的意思是逆向文件频率（inverse Document frequency）。TF-IDF是传统的统计算法，用于评估一个词在一个文档集中对于某一个文档的重要程度。它与这个词在当前文档中的词频成正比，与文档集中的其他词频成反比。这种计算方式能有效避免常用词对关键词的影响，提高了关键词与文章之间的相关性。

TF指的是某词在文章中出现的总次数，该指标通常会被归一化定义为TF=（某词在文档中出现的次数/文档的总词量），这样可以防止结果偏向过长的文档（同一个词语在长文档里通常会具有比短文档更高的词频）。IDF逆向文档频率，包含某词语的文档越少，IDF值越大，说明该词语具有很强的区分能力，IDF=loge（语料库中文档总数/包含该词的文档数+1），+1的原因是避免分母为0。TFIDF=TFxIDF，TFIDF值越大表示该特征词对这个文本的重要性越大。



假设我们现在有一片长文叫做《量化系统架构设计》词频高在文章中往往是停用词，“的”，“是”，“了”等，这些在文档中最常见但对结果毫无帮助、需要过滤掉的词，用TF可以统计到这些停用词并把它们过滤。当高频词过滤后就只需考虑剩下的有实际意义的词。

但这样又会遇到了另一个问题，我们可能发现"量化"、"系统"、"架构"这三个词的出现次数一样多。这是不是意味着，作为关键词，它们的重要性是一样的？事实上系统应该在其他文章比较常见，所以在关键词排序上，“量化”和“架构”应该排在“系统”前面，这个时候就需要IDF，IDF会给常见的词较小的权重，它的大小与一个词的常见程度成反比。



```python
from sklearn.feature_extraction.text import CountVectorizer

corpus = ["我 来到 风景 非常  美丽 的 杭州 喝 到了 非常 好喝 的 龙井"]
cv = CountVectorizer()
cv_fit = cv.fit_transform(corpus)
print(cv.get_feature_names())  // ['到了', '好喝', '来到', '杭州', '美丽', '非常', '风景', '龙井']
print(cv_fit.toarray())  // [[1 1 1 1 1 2 1 1]]
```





```python
# encoding=utf-8
import jieba

jieba.enable_paddle()# 启动paddle模式。 0.40版之后开始支持，早期版本不支持
strs=["我来到北京清华大学","乒乓球拍卖完了","中国科学技术大学"]
for str in strs:
    seg_list = jieba.cut(str,use_paddle=True) # 使用paddle模式
    print("Paddle Mode: " + '/'.join(list(seg_list)))

seg_list = jieba.cut("我来到北京清华大学", cut_all=True)
print("Full Mode: " + "/ ".join(seg_list))  # 全模式

seg_list = jieba.cut("我来到北京清华大学", cut_all=False)
print("Default Mode: " + "/ ".join(seg_list))  # 精确模式

seg_list = jieba.cut("他来到了网易杭研大厦")  # 默认是精确模式
print(", ".join(seg_list))

seg_list = jieba.cut_for_search("小明硕士毕业于中国科学院计算所，后在日本京都大学深造")  # 搜索引擎模式
print(", ".join(seg_list))
```

```
【全模式】: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学

【精确模式】: 我/ 来到/ 北京/ 清华大学

【新词识别】：他, 来到, 了, 网易, 杭研, 大厦    (此处，“杭研”并没有在词典中，但是也被Viterbi算法识别出来了)

【搜索引擎模式】： 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造
```



```python
sentence = '全国港澳研究会会长徐泽在会上发言指出，学习系列重要讲话要深刻领会 主席关于香港回归后的宪制基础和宪制秩序的论述，这是过去20年特别是中共十八大以来"一国两制"在香港实践取得成功的根本经验。首先，要在夯实 香港的宪制基础、巩固香港的宪制秩序上着力。只有牢牢确立起"一国两制"的宪制秩序，才能保证"一国两制"实践不走样 、不变形。其次，要在完善基本法实施的制度和机制上用功。中央直接行使的权力和特区高度自治权的结合是特区宪制秩 序不可或缺的两个方面，同时必须切实建立以行政长官为核心的行政主导体制。第三，要切实加强香港社会特别是针对公 职人员和青少年的宪法、基本法宣传，牢固树立"一国"意识，坚守"一国"原则。第四，要努力在全社会形成聚焦发展、抵 制泛政治化的氛围和势能，全面准确理解和落实基本法有关经济事务的规定，使香港继续在国家发展中发挥独特作用并由 此让最广大民众获得更实在的利益。'
# topK :  返回几个 TF/IDF 权重最大的关键词，默认值为 20
# withWeight :是否一并返回关键词权重值，默认值为 False
# allowPOS: 仅包括指定词性的词，默认值为空，即不筛选
keywords = jieba.analyse.extract_tags(sentence, topK=20, withWeight=True, allowPOS=('n', 'nr', 'ns'))
for item in keywords:
    print(item[0], item[1])
```

```
宪制 1.3431386920067796
基本法 0.5232081223372882
香港 0.4925521903983051
秩序 0.37291551977135595
特区 0.307537759819322
香港回归 0.21210819137118644
徐泽 0.20262317801525423
政治化 0.1875841408118644
走样 0.18569896055593219
势能 0.1692992312974576
用功 0.1631188395416949
基础 0.16146544425491527
行政长官 0.16010729416474578
社会 0.15218715730745763
研究会 0.14222524263305086
青少年 0.13773095095644067
氛围 0.13282868547949153
会长 0.13202051377067797
变形 0.13020470393694916
着力 0.12551545925491525
```



## 优缺点



TF-IDF的优点是简单快速，而且容易理解。缺点是有时候用**词频**来衡量文章中的一个词的重要性不够全面，有时候重要的词出现的可能不够多，而且这种计算无法体现位置信息，无法体现词在上下文的重要性。如果要体现词的上下文结构，那么你可能需要使用word2vec算法来支持。





